{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af573d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " the_input (InputLayer)         [(None, 2000, 80)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1000, 128)    30848       ['the_input[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1000, 128)   512         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1000, 128)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1000, 128)    0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 500, 128)     49280       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 500, 128)    512         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 500, 128)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 500, 128)     0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 500, 256)     164096      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 500, 256)    1024        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 500, 256)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 500, 256)     0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 500, 256)     327936      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 500, 256)    1024        ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 500, 256)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 500, 256)     0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 500, 256)     327936      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 500, 256)    1024        ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 256)         0           ['batch_normalization_6[0][0]']  \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 500, 256)     33024       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 500, 256)     33024       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           8224        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 500, 256)    1024        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 500, 256)    1024        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          8448        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 500, 256)     0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 500, 256)     0           ['batch_normalization_6[0][0]',  \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 500, 256)     0           ['add[0][0]',                    \n",
      "                                                                  'multiply[0][0]']               \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 500, 256)     0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 500, 256)     0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 500, 256)     459008      ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 500, 256)    1024        ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 500, 256)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 500, 256)     0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 500, 256)     459008      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 500, 256)    1024        ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 500, 256)     0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 500, 256)     0           ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 500, 256)     459008      ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 500, 256)    1024        ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 256)         0           ['batch_normalization_11[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 500, 256)     65792       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 500, 256)     65792       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           8224        ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 500, 256)    1024        ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 500, 256)    1024        ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          8448        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 500, 256)     0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 500, 256)     0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 500, 256)     0           ['add_2[0][0]',                  \n",
      "                                                                  'multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 500, 256)     0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 500, 256)     0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 500, 256)     590080      ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 500, 256)    1024        ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 500, 256)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 500, 256)     0           ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 500, 256)     590080      ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 500, 256)    1024        ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 500, 256)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 500, 256)     0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 500, 256)     590080      ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 500, 256)    1024        ['conv1d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 256)         0           ['batch_normalization_16[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 500, 256)     65792       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 500, 256)     65792       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 32)           8224        ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 500, 256)    1024        ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 500, 256)    1024        ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 256)          8448        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 500, 256)     0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 500, 256)     0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 500, 256)     0           ['add_4[0][0]',                  \n",
      "                                                                  'multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 500, 256)     0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 500, 256)     0           ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 500, 512)     1442304     ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 500, 512)    2048        ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 500, 512)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 500, 512)     0           ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 500, 512)     262656      ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 500, 512)    2048        ['conv1d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 500, 512)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 500, 512)     0           ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 500, 80)      41040       ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " Final (Activation)             (None, 500, 80)      0           ['conv1d_19[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,193,072\n",
      "Trainable params: 6,182,832\n",
      "Non-trainable params: 10,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "2025-06-25 20:41:25.377700: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'ctc/scan/while/Fill/ctc/stack_1' with dtype int32 and shape [1]\n",
      "\t [[{{node ctc/scan/while/Fill/ctc/stack_1}}]]\n",
      "2025-06-25 20:41:25.377748: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'ctc/scan/while/Fill/ctc/stack_1' with dtype int32 and shape [1]\n",
      "\t [[{{node ctc/scan/while/Fill/ctc/stack_1}}]]\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intializing from checkpoint :  ../weights/saved_checkpoint.hdf5\n",
      "Init weights loaded successfully....\n",
      "loading metdata...\n",
      "Training Samples :  6482\n",
      "Validation Samples :  976\n",
      "Test Samples :  2915\n",
      "CharList Size :  79\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Documents/learn/MSE/deepLearning/Easter2/src/easter_model.py:271: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n",
      "2025-06-25 20:41:26.010577: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-25 20:41:26.015136: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2025-06-25 20:41:26.319782: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'model_1/ctc/scan/while/Fill/model_1/ctc/stack_1' with dtype int32 and shape [1]\n",
      "\t [[{{node model_1/ctc/scan/while/Fill/model_1/ctc/stack_1}}]]\n",
      "2025-06-25 20:41:26.319829: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'model_1/ctc/scan/while/Fill/model_1/ctc/stack_1' with dtype int32 and shape [1]\n",
      "\t [[{{node model_1/ctc/scan/while/Fill/model_1/ctc/stack_1}}]]\n",
      "2025-06-25 20:41:27.126636: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'model_1/ctc/scan/while/Fill/model_1/ctc/stack_1' with dtype int32 and shape [1]\n",
      "\t [[{{node model_1/ctc/scan/while/Fill/model_1/ctc/stack_1}}]]\n",
      "2025-06-25 20:41:27.126688: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'model_1/ctc/scan/while/Fill/model_1/ctc/stack_1' with dtype int32 and shape [1]\n",
      "\t [[{{node model_1/ctc/scan/while/Fill/model_1/ctc/stack_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - ETA: 0s - loss: 9.8275"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 20:47:29.083682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-06-25 20:47:29.250282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'model_1/ctc/scan/while/Fill/model_1/ctc/stack_1' with dtype int32 and shape [1]\n",
      "\t [[{{node model_1/ctc/scan/while/Fill/model_1/ctc/stack_1}}]]\n",
      "2025-06-25 20:47:29.250326: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'model_1/ctc/scan/while/Fill/model_1/ctc/stack_1' with dtype int32 and shape [1]\n",
      "\t [[{{node model_1/ctc/scan/while/Fill/model_1/ctc/stack_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 377s 2s/step - loss: 9.8275 - val_loss: 10.8095\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.8983\n",
      "Epoch 2: saving model to ../weights/EASTER2--02--9.90.hdf5\n",
      "202/202 [==============================] - 371s 2s/step - loss: 9.8983 - val_loss: 10.8664\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 373s 2s/step - loss: 10.0272 - val_loss: 10.1452\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.0779\n",
      "Epoch 4: saving model to ../weights/EASTER2--04--10.08.hdf5\n",
      "202/202 [==============================] - 371s 2s/step - loss: 10.0779 - val_loss: 9.2768\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 371s 2s/step - loss: 10.1570 - val_loss: 9.6737\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.2819\n",
      "Epoch 6: saving model to ../weights/EASTER2--06--10.28.hdf5\n",
      "202/202 [==============================] - 371s 2s/step - loss: 10.2819 - val_loss: 9.7932\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 371s 2s/step - loss: 10.0744 - val_loss: 9.9868\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.1683\n",
      "Epoch 8: saving model to ../weights/EASTER2--08--10.17.hdf5\n",
      "202/202 [==============================] - 370s 2s/step - loss: 10.1683 - val_loss: 9.5712\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 372s 2s/step - loss: 10.0118 - val_loss: 9.3154\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.1818\n",
      "Epoch 10: saving model to ../weights/EASTER2--10--10.18.hdf5\n",
      "202/202 [==============================] - 370s 2s/step - loss: 10.1818 - val_loss: 9.2759\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 372s 2s/step - loss: 10.0465 - val_loss: 9.4527\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.9567\n",
      "Epoch 12: saving model to ../weights/EASTER2--12--9.96.hdf5\n",
      "202/202 [==============================] - 371s 2s/step - loss: 9.9567 - val_loss: 9.2600\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 371s 2s/step - loss: 10.0838 - val_loss: 8.9081\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.1557\n",
      "Epoch 14: saving model to ../weights/EASTER2--14--10.16.hdf5\n",
      "202/202 [==============================] - 372s 2s/step - loss: 10.1557 - val_loss: 10.1349\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 373s 2s/step - loss: 9.9761 - val_loss: 9.3547\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.2590\n",
      "Epoch 16: saving model to ../weights/EASTER2--16--10.26.hdf5\n",
      "202/202 [==============================] - 372s 2s/step - loss: 10.2590 - val_loss: 9.4395\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 372s 2s/step - loss: 10.1881 - val_loss: 9.1292\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.3255\n",
      "Epoch 18: saving model to ../weights/EASTER2--18--10.33.hdf5\n",
      "202/202 [==============================] - 372s 2s/step - loss: 10.3255 - val_loss: 9.6407\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 374s 2s/step - loss: 10.0707 - val_loss: 9.3121\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.0819\n",
      "Epoch 20: saving model to ../weights/EASTER2--20--10.08.hdf5\n",
      "202/202 [==============================] - 372s 2s/step - loss: 10.0819 - val_loss: 9.0820\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 372s 2s/step - loss: 10.0662 - val_loss: 9.3218\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.2440\n",
      "Epoch 22: saving model to ../weights/EASTER2--22--10.24.hdf5\n",
      "202/202 [==============================] - 373s 2s/step - loss: 10.2440 - val_loss: 9.5344\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 372s 2s/step - loss: 10.0724 - val_loss: 9.7098\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.0098\n",
      "Epoch 24: saving model to ../weights/EASTER2--24--10.01.hdf5\n",
      "202/202 [==============================] - 373s 2s/step - loss: 10.0098 - val_loss: 9.4494\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 10.2516 - val_loss: 9.6377\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.1503\n",
      "Epoch 26: saving model to ../weights/EASTER2--26--10.15.hdf5\n",
      "202/202 [==============================] - 373s 2s/step - loss: 10.1503 - val_loss: 8.9099\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.9582 - val_loss: 9.1972\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.1830\n",
      "Epoch 28: saving model to ../weights/EASTER2--28--10.18.hdf5\n",
      "202/202 [==============================] - 370s 2s/step - loss: 10.1830 - val_loss: 9.6642\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 10.1606 - val_loss: 9.1645\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.9727\n",
      "Epoch 30: saving model to ../weights/EASTER2--30--9.97.hdf5\n",
      "202/202 [==============================] - 371s 2s/step - loss: 9.9727 - val_loss: 8.8965\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.8937 - val_loss: 9.1519\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.9091\n",
      "Epoch 32: saving model to ../weights/EASTER2--32--9.91.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.9091 - val_loss: 9.2516\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 10.0402 - val_loss: 8.9937\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.1397\n",
      "Epoch 34: saving model to ../weights/EASTER2--34--10.14.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 10.1397 - val_loss: 10.1145\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 10.1737 - val_loss: 9.1436\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.0503\n",
      "Epoch 36: saving model to ../weights/EASTER2--36--10.05.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 10.0503 - val_loss: 9.4736\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.8326 - val_loss: 8.9286\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.8805\n",
      "Epoch 38: saving model to ../weights/EASTER2--38--9.88.hdf5\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.8805 - val_loss: 9.0862\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 372s 2s/step - loss: 10.6045 - val_loss: 9.4286\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.5020\n",
      "Epoch 40: saving model to ../weights/EASTER2--40--10.50.hdf5\n",
      "202/202 [==============================] - 368s 2s/step - loss: 10.5020 - val_loss: 9.4931\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 371s 2s/step - loss: 9.9217 - val_loss: 9.0402\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.9159\n",
      "Epoch 42: saving model to ../weights/EASTER2--42--9.92.hdf5\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.9159 - val_loss: 9.4917\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 371s 2s/step - loss: 9.9886 - val_loss: 9.6159\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.7985\n",
      "Epoch 44: saving model to ../weights/EASTER2--44--9.80.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.7985 - val_loss: 8.9510\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 10.7241 - val_loss: 9.2535\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.1770\n",
      "Epoch 46: saving model to ../weights/EASTER2--46--10.18.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 10.1770 - val_loss: 9.2291\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 10.0137 - val_loss: 9.4183\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.2488\n",
      "Epoch 48: saving model to ../weights/EASTER2--48--10.25.hdf5\n",
      "202/202 [==============================] - 372s 2s/step - loss: 10.2488 - val_loss: 9.9102\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 371s 2s/step - loss: 10.8752 - val_loss: 9.6085\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.0839\n",
      "Epoch 50: saving model to ../weights/EASTER2--50--10.08.hdf5\n",
      "202/202 [==============================] - 370s 2s/step - loss: 10.0839 - val_loss: 9.0845\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 373s 2s/step - loss: 9.9509 - val_loss: 9.1687\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.9121\n",
      "Epoch 52: saving model to ../weights/EASTER2--52--9.91.hdf5\n",
      "202/202 [==============================] - 372s 2s/step - loss: 9.9121 - val_loss: 9.0822\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 371s 2s/step - loss: 9.9511 - val_loss: 9.3735\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.7174\n",
      "Epoch 54: saving model to ../weights/EASTER2--54--9.72.hdf5\n",
      "202/202 [==============================] - 371s 2s/step - loss: 9.7174 - val_loss: 9.1764\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 371s 2s/step - loss: 9.8291 - val_loss: 9.2903\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 13.3509\n",
      "Epoch 56: saving model to ../weights/EASTER2--56--13.35.hdf5\n",
      "202/202 [==============================] - 371s 2s/step - loss: 13.3509 - val_loss: 9.6800\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 10.6315 - val_loss: 9.1724\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.1748\n",
      "Epoch 58: saving model to ../weights/EASTER2--58--10.17.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 10.1748 - val_loss: 9.2263\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 10.1316 - val_loss: 8.8632\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.0417\n",
      "Epoch 60: saving model to ../weights/EASTER2--60--10.04.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 10.0417 - val_loss: 9.0404\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.9522 - val_loss: 8.7612\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.8216\n",
      "Epoch 62: saving model to ../weights/EASTER2--62--9.82.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.8216 - val_loss: 8.6995\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.7358 - val_loss: 9.0282\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.6904\n",
      "Epoch 64: saving model to ../weights/EASTER2--64--9.69.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.6904 - val_loss: 8.5942\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.6663 - val_loss: 8.7922\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.7629\n",
      "Epoch 66: saving model to ../weights/EASTER2--66--9.76.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.7629 - val_loss: 9.2842\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.6991 - val_loss: 8.6526\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.5679\n",
      "Epoch 68: saving model to ../weights/EASTER2--68--9.57.hdf5\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.5679 - val_loss: 8.7918\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.6219 - val_loss: 8.6435\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.7859\n",
      "Epoch 70: saving model to ../weights/EASTER2--70--9.79.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.7859 - val_loss: 8.8546\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.7403 - val_loss: 9.1435\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 11.0835\n",
      "Epoch 72: saving model to ../weights/EASTER2--72--11.08.hdf5\n",
      "202/202 [==============================] - 371s 2s/step - loss: 11.0835 - val_loss: 9.7402\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 10.1410 - val_loss: 8.8386\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.7888\n",
      "Epoch 74: saving model to ../weights/EASTER2--74--9.79.hdf5\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.7888 - val_loss: 9.2823\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.8579 - val_loss: 9.0922\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 10.1100\n",
      "Epoch 76: saving model to ../weights/EASTER2--76--10.11.hdf5\n",
      "202/202 [==============================] - 371s 2s/step - loss: 10.1100 - val_loss: 9.1210\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.7770 - val_loss: 9.1287\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.5969\n",
      "Epoch 78: saving model to ../weights/EASTER2--78--9.60.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.5969 - val_loss: 8.8930\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.6987 - val_loss: 9.1714\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.5955\n",
      "Epoch 80: saving model to ../weights/EASTER2--80--9.60.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.5955 - val_loss: 8.9986\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.6583 - val_loss: 8.7740\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.6716\n",
      "Epoch 82: saving model to ../weights/EASTER2--82--9.67.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.6716 - val_loss: 8.8629\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.5185 - val_loss: 8.8057\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.5155\n",
      "Epoch 84: saving model to ../weights/EASTER2--84--9.52.hdf5\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.5155 - val_loss: 9.0390\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.6957 - val_loss: 8.7896\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.5714\n",
      "Epoch 86: saving model to ../weights/EASTER2--86--9.57.hdf5\n",
      "202/202 [==============================] - 371s 2s/step - loss: 9.5714 - val_loss: 9.0422\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.4670 - val_loss: 9.4894\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.7581\n",
      "Epoch 88: saving model to ../weights/EASTER2--88--9.76.hdf5\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.7581 - val_loss: 8.9017\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.6353 - val_loss: 9.2743\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.6318\n",
      "Epoch 90: saving model to ../weights/EASTER2--90--9.63.hdf5\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.6318 - val_loss: 8.9967\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 369s 2s/step - loss: 9.6483 - val_loss: 9.2822\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.5532\n",
      "Epoch 92: saving model to ../weights/EASTER2--92--9.55.hdf5\n",
      "202/202 [==============================] - 368s 2s/step - loss: 9.5532 - val_loss: 8.6874\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 368s 2s/step - loss: 9.4830 - val_loss: 8.8975\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.5412\n",
      "Epoch 94: saving model to ../weights/EASTER2--94--9.54.hdf5\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.5412 - val_loss: 8.9712\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.4829 - val_loss: 8.8888\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.6672\n",
      "Epoch 96: saving model to ../weights/EASTER2--96--9.67.hdf5\n",
      "202/202 [==============================] - 370s 2s/step - loss: 9.6672 - val_loss: 9.0658\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 368s 2s/step - loss: 9.4426 - val_loss: 8.7225\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.3098\n",
      "Epoch 98: saving model to ../weights/EASTER2--98--9.31.hdf5\n",
      "202/202 [==============================] - 382s 2s/step - loss: 9.3098 - val_loss: 8.7642\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 408s 2s/step - loss: 9.5178 - val_loss: 8.8517\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - ETA: 0s - loss: 9.5133\n",
      "Epoch 100: saving model to ../weights/EASTER2--100--9.51.hdf5\n",
      "202/202 [==============================] - 412s 2s/step - loss: 9.5133 - val_loss: 9.2011\n"
     ]
    }
   ],
   "source": [
    "from easter_model import train\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab4fabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "542bd7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"../weights/saved_checkpoint.hdf5\"))  # True th file tn ti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2deedf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac1eb627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading metdata...\n",
      "loading checkpoint...\n",
      "calculating results...\n",
      "Unable to Load Checkpoint.\n",
      "Using Test Partition\n",
      "Number of Samples :  2915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2915 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpredict\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m test_on_iam\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtest_on_iam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEmpty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/learn/MSE/deepLearning/Easter2/src/predict.py:88\u001b[39m, in \u001b[36mtest_on_iam\u001b[39m\u001b[34m(show, partition, uncased, checkpoint)\u001b[39m\n\u001b[32m     86\u001b[39m img = imgs[i]\n\u001b[32m     87\u001b[39m truth = truths[i].strip(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m(img)\n\u001b[32m     89\u001b[39m prediction = decoder(output, charlist)\n\u001b[32m     90\u001b[39m output = (prediction[\u001b[32m0\u001b[39m].strip(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "from predict import test_on_iam\n",
    "test_on_iam(show=True, checkpoint=\"Empty\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
